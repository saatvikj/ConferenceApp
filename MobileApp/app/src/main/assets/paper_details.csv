title,authors,topics,venue,time,abstract
Kernelized Bayesian Transfer Learning,"Letha Lyvers,Eusebio Brinkman","APP: Biomedical / Bioinformatics
NMLA: Bayesian Learning
NMLA: Kernel Methods
NMLA: Transfer, Adaptation, Multitask Learning
VIS: Object Recognition","Hall A, Building 1","Sunday,2 Dec 18,10:30-11:30","Transfer learning considers related but distinct tasks defined on heterogenous domains and tries to transfer knowledge between these tasks to improve generalization performance. It is particularly useful when we do not have sufficient amount of labeled training data in some tasks, which may be very costly, laborious, or even infeasible to obtain. Instead, learning the tasks jointly enables us to effectively increase the amount of labeled training data. In this paper, we formulate a kernelized Bayesian transfer learning framework that is a principled combination of kernel-based dimensionality reduction models with task-specific projection matrices to find a shared subspace and a coupled classification model for all of the tasks in this subspace. Our two main contributions are: (i) two novel probabilistic models for binary and multiclass classification, and (ii) very efficient variational approximation procedures for these models. We illustrate the generalization performance of our algorithms on two different applications. In computer vision experiments, our method outperforms the state-of-the-art algorithms on nine out of 12 benchmark supervised domain adaptation experiments defined on two object recognition data sets. In cancer biology experiments, we use our algorithm to predict mutation status of important cancer genes from gene expression profiles using two distinct cancer populations, namely, patient-derived primary tumor data and in-vitro-derived cancer cell line data. We show that we can increase our generalization performance on primary tumors using cell lines as an auxiliary data source."
"""Source Free"" Transfer Learning for Text Classification","Vallie Boissonneault,Alisha Bunge,Gayla Sprague","AIW: Knowledge acquisition from the web
AIW: Machine learning and the web
NMLA: Transfer, Adaptation, Multitask Learning","Hall B, Building 2","Sunday,2 Dec 18,10:50-13:00","Transfer learning uses relevant auxiliary data to help the learning task in a target domain where labeled data are usually insufficient to train an accurate model. Given appropriate auxiliary data, researchers have proposed many transfer learning models. How to find such auxiliary data, however, is of little research in the past. In this paper, we focus on this auxiliary data retrieval problem, and propose a transfer learning framework that effectively selects helpful auxiliary data from an open knowledge space (e.g. the World Wide Web). Because there is no need of manually selecting auxiliary data for different target domain tasks, we call our framework Source Free Transfer Learning (SFTL). For each target domain task, SFTL framework iteratively queries for the helpful auxiliary data based on the learned model and then updates the model using the retrieved auxiliary data. We highlight the automatic constructions of queries and the robustness of the SFTL framework. Our experiments on the 20 NewsGroup dataset and the Google search snippets dataset suggest that the new framework is capable to have the comparable performance to those state-of-the-art methods with dedicated selections of auxiliary data."
A Generalization of Probabilistic Serial to Randomized Social Choice,"Darwin Garlock,James Lex","GTEP: Game Theory
GTEP: Social Choice / Voting","Hall B, Building 1","Sunday,2 Dec 18,11:30-12:30","The probabilistic serial (PS) rule is one of the most well-established and desirable rules for the random assignment problem. We present the egalitarian simultaneous reservation (ESR) social decision scheme — an extension of PS to the more general setting of randomized social choice. ESR also generalizes an egalitarian rule from the literature which is defined only for dichotomous preferences. We consider various desirable fairness, efficiency, and strategic properties of ESR and show that it compares favourably against other social decision schemes. Finally, we define a more general class of social decision schemes called Simultaneous Reservation (SR), that contains ESR as well as the serial dictatorship rules. We show that outcomes of SR characterize efficiency with respect to a natural refinement of stochastic dominance."
Lifetime Lexical Variation in Social Media,"Darwin Garlock,Doloris Houge,Kathey Calmes","AIW: Web personalization and user modeling
NLPTM: Information Extraction
NLPTM: Natural Language Processing (General/Other)","Hall A, Building 2","Sunday,2 Dec 18,14:00-15:30","As the rapid growth of online social media attracts a large number of Internet users, the large volume of content generated by these users also provides us with an opportunity to study the lexical variations of people of different age. In this paper, we present a latent variable model that jointly models the lexical content of tweets and Twitter users' age. Our model inherently assumes that a topic has not only a word distribution but also an age distribution. We propose a Gibbs-EM algorithm to perform inference on our model. Empirical evaluation shows that our model can generate meaningful age-specific topics such as ""school"" for teenagers and ""health"" for older people. Our model also performs age prediction better than a number of baseline methods."
Hybrid Singular Value Thresholding for Tensor Completion,"Noella Hayslip,Alisha Bunge","KRR: Knowledge Representation (General/Other)
MLA: Machine Learning Applications (General/other)
NMLA: Data Mining and Knowledge Discovery
NMLA: Dimension Reduction/Feature Selection
VIS: Statistical Methods and Learning","Hall A, Building 1","Sunday,2 Dec 18,15:00-16:30","In this paper, we study the low-rank tensor completion problem, where a high-order tensor with missing entries is given and the goal is to complete the tensor. We propose to minimize a new convex objective function, based on log sum of exponentials of nuclear norms, that promotes the low-rankness of unfolding matrices of the completed tensor. We show for the first time that the proximal operator to this objective function is readily computable through a hybrid singular value thresholding scheme. This leads to a new solution to high-order (low-rank) tensor completion via convex relaxation. We show that this convex relaxation and the resulting solution are much more effective than existing tensor completion methods
(including those also based on minimizing ranks of unfolding matrices). The hybrid singular value thresholding scheme can be applied to any problem where the goal is
to minimize the maximum rank of a set of low-rank matrices."
Locality Preserving Hashing,"Katharina Schrupp,Noella Hayslip",VIS: Image and Video Retrieval,"Hall B, Building 2","Monday,3 Dec 18,10:30-11:30","Hashing has recently attracted considerable attention for large scale similarity search. However, learning compact codes with good performance is still a challenge. In many cases, the real-world data lies on a low-dimensional manifold embedded in high-dimensional ambient space. To capture meaningful neighbors, a compact hashing representation should uncover the intrinsic geometric structure of the manifold, e.g., the neighborhood relationships between subregions. Most existing hashing methods only consider this issue during mapping data points into certain projected dimensions. When getting the binary codes, they either directly quantize the projected values with a threshold, or use an orthogonal matrix to refine the initial projection matrix, which both consider projection and quantization separately, and it will not well preserve the locality structure in the whole learning process. In this paper, we propose a novel hashing algorithm called Locality Preserving Hashing to effectively solve the above problems. Specifically, we learn a set of locality preserving projections with a joint optimization framework, which minimizes the average projection distance and quantization loss simultaneously. Experimental comparisons with other state-of-the-art methods on two large scale databases demonstrate the effectiveness and efficiency of our method."
Discovering Better AAAI Keywords via Clustering with Crowd-sourced Constraints,"Noella Hayslip,Roselyn Picklesimer,Youlanda Griffie",MLA: Applications of Unsupervised Learning,"Hall B, Building 1","Monday,3 Dec 18,10:50-13:00","Selecting good conference keywords is important because they often determine the composition of review committees and hence which papers are reviewed by whom. But presently conference keywords are generated in an ad-hoc manner by a small set of conference organizers. This approach is plainly not ideal. There is no guarantee, for example, that the generated keyword set aligns with what the community is actually working on and submitting to the conference in a given year. This is especially true in fast moving fields such as AI. The problem is exacerbated by the tendency of organizers to draw heavily on preceding years' keyword lists when generating a new set. Rather than a select few ordaining a keyword set that that represents AI at large, it would be preferable to generate these keywords more directly from the data, with input from research community members. To this end, we solicited feedback from seven AAAI PC members regarding a previously existing keyword set and used these 'crowd-sourced constraints' to inform a clustering over the abstracts of all submissions to AAAI 2013. We show that the keywords discovered via this data-driven, human-in-the-loop method are at least as preferred (by AAAI PC members) as 2013's manually generated set, and that they include categories previously overlooked by organizers. Many of the discovered terms were used for this year's conference."
Online Classification Using a Voted RDA Method,Ericka Cowger,"MLA: Machine Learning Applications (General/other)
NLPML: Natural Language Processing (General/Other)
NMLA: Big Data / Scalability
NMLA: Classification
NMLA: Online Learning","Hall A, Building 2","Monday,3 Dec 18,11:30-12:30","We propose a voted dual averaging method for online
classification problems with explicit regularization.
This method employs the update rule of the regularized
dual averaging (RDA) method proposed by Xiao, but
only on the subsequence of training examples where a
classification error is made. We derive a bound on the
number of mistakes made by this method on the training
set, as well as its generalization error rate.We also introduce
the concept of relative strength of regularization,
and show how it affects the mistake bound and generalization
performance. We examine the method using
ℓ1-regularization on a large-scale natural language processing
task, and obtained state-of-the-art classification
performance with fairly sparse models."
Fraudulent Support Telephone Number Identification Based on Co-occurrence Information on the Web,"Glady Mahan,Doloris Houge,Vallie Boissonneault","AIW: Enhancing web search and information retrieval
AIW: Recognizing web spam such as link farms and splogs",Main Room,"Monday,3 Dec 18,14:00-15:30","""Fraudulent support phones"" refers to the misleading telephone numbers placed on Web pages or other media that claim to provide services with which they are not associated. Most fraudulent support phone information is found on search engine result pages (SERPs), and such information substantially degrades the search engine user experience. In this paper, we propose an approach to identify fraudulent support telephone numbers on the Web based on the co-occurrence relations between telephone numbers that appear on SERPs. We start from a small set of seed official support phone numbers and seed fraudulent numbers. Then, we construct a co-occurrence graph according to the co-occurrence relationships of the telephone numbers that appear on Web pages. Additionally, we take the page layout information into consideration on the assumption that telephone numbers that appear in nearby page blocks should be regarded as more closely related. Finally, we develop a propagation algorithm to diffuse the trust scores of seed official support phone numbers and the distrust scores of the seed fraudulent numbers on the co-occurrence graph to detect additional fraudulent numbers. Experimental results based on over 1.5 million SERPs produced by a popular Chinese commercial search engine indicate that our approach outperforms TrustRank, Anti-TrustRank and Good-Bad Rank algorithms by achieving an AUC value of over 0.90."